#!/bin/bash
# Complete Ollama Optimization Installation Script

set -e  # Exit on error

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘     ğŸš€ Ollama Performance Optimization Installer          â•‘"
echo "â•‘     Optimized for: 8-core/16-thread, 32GB RAM Mac        â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Check if Ollama is installed
if ! command -v ollama &> /dev/null; then
    echo -e "${RED}âŒ Ollama is not installed${NC}"
    echo "Install it with: brew install ollama"
    exit 1
fi

echo -e "${GREEN}âœ… Ollama found: $(ollama --version 2>&1 | grep -o 'version is.*')${NC}"
echo ""

# Step 1: Setup environment variables
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ“ Step 1: Setting up environment variables..."
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

chmod +x setup_ollama_performance.sh
./setup_ollama_performance.sh

source ~/.ollama/env_config.sh

echo -e "${GREEN}âœ… Environment variables configured${NC}"
echo ""

# Step 2: Ask about LaunchD service
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸš€ Step 2: LaunchD Service (Optional)"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "Install Ollama as a system service to auto-start on boot?"
echo -e "${YELLOW}This requires sudo access${NC}"
read -p "Install LaunchD service? (y/N): " -n 1 -r
echo ""

if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "Installing LaunchD service..."
    
    # Stop existing Ollama if running
    pkill ollama 2>/dev/null || true
    
    # Copy plist
    sudo cp com.ollama.optimized.plist /Library/LaunchDaemons/
    sudo chown root:wheel /Library/LaunchDaemons/com.ollama.optimized.plist
    sudo chmod 644 /Library/LaunchDaemons/com.ollama.optimized.plist
    
    # Load service
    sudo launchctl load /Library/LaunchDaemons/com.ollama.optimized.plist
    
    echo -e "${GREEN}âœ… LaunchD service installed and started${NC}"
    sleep 2
else
    echo "Skipping LaunchD service. Starting Ollama manually..."
    ollama serve > /tmp/ollama.log 2>&1 &
    echo -e "${GREEN}âœ… Ollama started manually${NC}"
    sleep 3
fi

echo ""

# Step 3: Verify Ollama is running
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ” Step 3: Verifying Ollama is running..."
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

for i in {1..10}; do
    if curl -s http://localhost:11434/api/version > /dev/null 2>&1; then
        echo -e "${GREEN}âœ… Ollama is running and responding${NC}"
        break
    fi
    echo "Waiting for Ollama to start... ($i/10)"
    sleep 1
done

if ! curl -s http://localhost:11434/api/version > /dev/null 2>&1; then
    echo -e "${RED}âŒ Ollama failed to start${NC}"
    echo "Check logs: tail -f /tmp/ollama.log"
    exit 1
fi

echo ""

# Step 4: Pull base models if needed
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ“¦ Step 4: Checking required models..."
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

MODELS=("codellama:13b" "deepseek-coder:6.7b" "llama3:latest")

for model in "${MODELS[@]}"; do
    if ollama list | grep -q "$model"; then
        echo -e "${GREEN}âœ… $model already available${NC}"
    else
        echo -e "${YELLOW}ğŸ“¥ Pulling $model (this may take a while)...${NC}"
        ollama pull "$model"
        echo -e "${GREEN}âœ… $model downloaded${NC}"
    fi
done

echo ""

# Step 5: Create optimized models
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "âš¡ Step 5: Creating optimized model variants..."
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

chmod +x create_optimized_models.sh
./create_optimized_models.sh

echo ""

# Step 6: IDE configuration info
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ¨ Step 6: IDE Configuration"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "Configuration files are ready for your IDEs:"
echo ""
echo "ğŸ“ Cursor:"
echo "   File: $(pwd)/cursor_settings.json"
echo "   Path: ~/Library/Application Support/Cursor/User/settings.json"
echo ""
echo "ğŸ“ VSCode:"
echo "   File: $(pwd)/vscode_settings.json"
echo "   Path: ~/Library/Application Support/Code/User/settings.json"
echo ""
echo "ğŸ“ Windsurf:"
echo "   File: $(pwd)/windsurf_settings.json"
echo "   Path: Check your Windsurf settings location"
echo ""
echo -e "${YELLOW}âš ï¸  Merge these settings manually with your existing IDE settings${NC}"
echo ""

# Step 7: Performance test
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ§ª Step 7: Performance Test"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
read -p "Run performance test? (y/N): " -n 1 -r
echo ""

if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "Testing fast-codellama..."
    echo ""
    time ollama run fast-codellama "Write a Python hello world function" --verbose
    echo ""
fi

# Success summary
echo ""
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘                  âœ… Installation Complete!                 â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "ğŸ¯ What's configured:"
echo "  âœ“ Environment variables optimized for 16 threads"
echo "  âœ“ Ollama running with maximum performance settings"
echo "  âœ“ 3 optimized model variants created"
echo "  âœ“ IDE configuration files ready"
echo ""
echo "ğŸš€ Quick Test Commands:"
echo "  ollama run fast-codellama 'Write a fibonacci function'"
echo "  ollama run fast-deepseek 'Complete: def hello():'"
echo "  ollama run fast-llama3 'Explain Python decorators briefly'"
echo ""
echo "ğŸ“Š Monitor Performance:"
echo "  top -pid \$(pgrep ollama)"
echo "  tail -f /tmp/ollama.log"
echo ""
echo "ğŸ“– Full documentation:"
echo "  cat $(pwd)/README.md"
echo ""
echo -e "${GREEN}Happy coding! ğŸ‰${NC}"
